{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define the path to your text file\n",
    "file_path = 'Block_stat_final.txt'\n",
    "\n",
    "\n",
    "# Read the file and process the data\n",
    "data = []\n",
    "res = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into parts based on spaces\n",
    "        parts = line.split()\n",
    "        if parts == []: continue\n",
    "        if len(parts) == 2:\n",
    "            if parts[0] not in res.keys():\n",
    "                res[parts[0]] = {}\n",
    "            res[parts[0]][parts[1]] = {}\n",
    "            method = parts[1]\n",
    "            dataset = parts[0]\n",
    "            cnt = 0\n",
    "        elif parts[0] != 'bias':\n",
    "            RR = float(parts[0])\n",
    "            PC = float(parts[1])\n",
    "            PQ = float(parts[2])\n",
    "            time_ = float(parts[4])\n",
    "            Fb = 2*PC *RR / (PC + RR)\n",
    "            res[dataset][method] = {'RR':round(RR,5), 'PC':round(PC,5), 'PQ':round(PQ,5), 'Fb':round(Fb,5), 'time':round(time_,5)}\n",
    "        else:\n",
    "            if cnt ==0:\n",
    "                RR_minor = float(parts[1])\n",
    "                PC_minor = float(parts[2])\n",
    "                PQ_minor = float(parts[3])\n",
    "                Fb_minor = float(parts[4])\n",
    "                res[dataset][method]['RR_minor'] = round(RR_minor,5)\n",
    "                res[dataset][method]['PC_minor'] = round(PC_minor,5)\n",
    "                res[dataset][method]['PQ_minor'] = round(PQ_minor,5)\n",
    "                res[dataset][method]['Fb_minor'] = round(Fb_minor,5)\n",
    "                cnt+=1\n",
    "            elif cnt ==1:\n",
    "                RR_major = float(parts[1])\n",
    "                Pc_major = float(parts[2])\n",
    "                PQ_major = float(parts[3])\n",
    "                Fb_major = float(parts[4])\n",
    "                res[dataset][method]['RR_major'] = round(RR_major,5)\n",
    "                res[dataset][method]['Pc_major'] = round(Pc_major,5)\n",
    "                res[dataset][method]['PQ_major'] = round(PQ_major,5)\n",
    "                res[dataset][method]['Fb_major'] = round(Fb_major,5)\n",
    "                cnt+=1\n",
    "            elif cnt==2:\n",
    "\n",
    "                RR_diff = float(parts[1])\n",
    "                Pc_diff = float(parts[2])\n",
    "                PQ_diff = float(parts[3])\n",
    "                Fb_diff = float(parts[4])\n",
    "                res[dataset][method]['RR_diff'] = round(RR_diff,5)\n",
    "                res[dataset][method]['Pc_diff'] = round(Pc_diff,5)\n",
    "                res[dataset][method]['PQ_diff'] = round(PQ_diff,5)\n",
    "                res[dataset][method]['Fb_diff'] = round(Fb_diff,5)\n",
    "                cnt+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "M_all = list(res['Beer'].keys())\n",
    "scatter_pnt = {}\n",
    "for M in M_all:\n",
    "    scatter_pnt[M] = []\n",
    "\n",
    "\n",
    "for k in list(res.keys()):\n",
    "    for M in M_all:\n",
    "        scatter_pnt[M].append([res[k][M]['RR'],res[k][M]['PQ']])\n",
    "\n",
    "   \n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'\\\\stdBlock',\n",
    "    'QGramsBlocking':'\\\\qgram',\n",
    "    'ExtendedQGramsBlocking':'\\\\exQgram',\n",
    "    'SuffixArraysBlocking':'\\\\suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'\\\\exSuffix',\n",
    "    'AUTO':'\\\\AutoBlock',\n",
    "    'CTT':'\\\\CTT'}\n",
    "\n",
    "\n",
    "\n",
    "TASKS = ['Amazon-Google', 'Walmart-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM', 'Beer', 'Fodors-Zagat', 'iTunes-Amazon']\n",
    "\n",
    "# Open a file in write mode\n",
    "with open('LATEX/exp1_latex.txt', 'w') as file:\n",
    "    for method in METHODS.keys():\n",
    "        for task in TASKS:\n",
    "            row = res[task][method]\n",
    "\n",
    "\n",
    "            if task == 'iTunes-Amazon':\n",
    "                file.write(f\"{row['RR']:.2f} & {row['PC']:.2f} & {row['PQ']:.2f} & {row['Fb']:.2f} \\\\\\\\\\n\")\n",
    "            elif task == 'Amazon-Google':\n",
    "                file.write(f\"{METHODS[method]} & \\n{row['RR']:.2f} & {row['PC']:.2f} & {row['PQ']:.2f} & {row['Fb']:.2f} & \\n\")\n",
    "            else:\n",
    "                file.write(f\"{row['RR']:.2f} & {row['PC']:.2f} & {row['PQ']:.2f} & {row['Fb']:.2f} & \\n\")\n",
    "\n",
    "        file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Open a file in write mode\n",
    "with open('LATEX/exp2_latex.txt', 'w') as file:\n",
    "    for method in METHODS.keys():\n",
    "        for task in TASKS:\n",
    "            row = res[task][method]\n",
    "\n",
    "            if task == 'iTunes-Amazon':\n",
    "                file.write(f\"{row['RR_diff']:.2f} & {row['Pc_diff']:.2f} & {row['Fb_diff']:.2f} \\\\\\\\\\n\")\n",
    "            elif task == 'Amazon-Google':\n",
    "                file.write(f\"{METHODS[method]} & \\n{row['RR_diff']:.2f} & {row['Pc_diff']:.2f} & {row['Fb_diff']:.2f} & \\n\")\n",
    "            else:\n",
    "                file.write(f\"{row['RR_diff']:.2f} & {row['Pc_diff']:.2f} & {row['Fb_diff']:.2f} & \\n\")\n",
    "\n",
    "        file.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "# Open a file in write mode\n",
    "with open('LATEX/exp3_latex.txt', 'w') as file:\n",
    "    for method in METHODS.keys():\n",
    "        for task in TASKS:\n",
    "            row = res[task][method]\n",
    "\n",
    "            if task == 'Fodors-Zagat':\n",
    "                file.write(f\"{row['RR_minor']:.2f} & {row['RR_major']:.2f} & {row['PC_minor']:.2f} & {row['Pc_major']:.2f} & {row['Fb_minor']:.2f} &  {row['Fb_major']:.2f} \\\\\\\\\\n\")\n",
    "            elif task == 'Amazon-Google':\n",
    "                file.write(f\"{METHODS[method]} & \\n{row['RR_minor']:.2f} & {row['RR_major']:.2f} & {row['PC_minor']:.2f} & {row['Pc_major']:.2f} & {row['Fb_minor']:.2f} &  {row['Fb_major']:.2f} & \\n\")\n",
    "            elif task in ['Walmart-Amazon','Beer']:\n",
    "                file.write(f\"{row['RR_minor']:.2f} & {row['RR_major']:.2f} & {row['PC_minor']:.2f} & {row['Pc_major']:.2f} & {row['Fb_minor']:.2f} &  {row['Fb_major']:.2f} & \\n\")\n",
    "\n",
    "        file.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to your text file\n",
    "file_path = 'tmp.txt'\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'\\\\stdBlock',\n",
    "    'QGramsBlocking':'\\\\qgram',\n",
    "    'ExtendedQGramsBlocking':'\\\\exQgram',\n",
    "    'SuffixArraysBlocking':'\\\\suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'\\\\exSuffix',\n",
    "    'AUTO':'\\\\AutoBlock',\n",
    "    'CTT':'\\\\CTT'}\n",
    "\n",
    "\n",
    "TASKS_dict = {'Walmart-Amazon':'\\\\walamz',\n",
    "          'Beer':'\\\\Beer',\n",
    "        'Amazon-Google':'\\\\amzgog',\n",
    "        'Fodors-Zagat':'\\\\FodorZag', 'iTunes-Amazon':'\\\\itunamz',\n",
    "          'DBLP-GoogleScholar':'\\\\DBLPGogS', 'DBLP-ACM':'\\\\DBLPACM'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'StandBlock',\n",
    "    'QGramsBlocking':'Q-Gram',\n",
    "    'ExtendedQGramsBlocking':'Ext-Q-Gram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'Ext-Suffix',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TASKS = ['Walmart-Amazon', 'Beer' ,'Amazon-Google', 'Fodors-Zagat', 'iTunes-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM']\n",
    "\n",
    "file_path = 'block_stat_time.txt'\n",
    "\n",
    "\n",
    "# Read the file and process the data\n",
    "data = []\n",
    "res = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into parts based on spaces\n",
    "        parts = line.split()\n",
    "        if parts == []: continue\n",
    "        try: \n",
    "            float(parts[0])\n",
    "            time_avg = float(parts[0])\n",
    "            time_std = float(parts[1])\n",
    "            res[dataset][method] = {'time_avg':round(time_avg,5), 'time_std':round(time_std,5)}\n",
    "        except:\n",
    "            if parts[0] not in res.keys():\n",
    "                res[parts[0]] = {}\n",
    "            res[parts[0]][parts[1]] = {}\n",
    "            method = parts[1]\n",
    "            dataset = parts[0]\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'StandBlock',\n",
    "    'QGramsBlocking':'Q-Gram',\n",
    "    'ExtendedQGramsBlocking':'Ext-Q-Gram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'Ext-Suffix',\n",
    "    'AUTO':'AUTO',\n",
    "    'CTT':'CTT'\n",
    "}\n",
    "\n",
    "with open('LATEX/exp_time.txt', 'w') as file:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS.keys():\n",
    "            if method not in ['AUTO','CTT']:\n",
    "                row = res[task][method]['time_avg']\n",
    "                row_std = res[task][method]['time_std']\n",
    "            \n",
    "            if row > 60: \n",
    "                row = row / 60\n",
    "                row_std = row_std / 60\n",
    "                flag = 'm'\n",
    "            else:\n",
    "                flag = 's'\n",
    "\n",
    "\n",
    "            if method == 'StandardBlocking':\n",
    "                if  str(round(row_std,1)) == '0.0':\n",
    "                    file.write(f\"{TASKS_dict[task]} & {row:.1f}{flag} & \")\n",
    "                else:\n",
    "                    file.write(f\"{TASKS_dict[task]} & {row:.1f}$\\\\pm${row_std:.1f}{flag} & \")\n",
    "            elif method == 'CTT':\n",
    "                # file.write(f\"{row:.1f}{flag}  \\\\\\\\ \\n\")\n",
    "                file.write(f\"-  \\\\\\\\ \")\n",
    "            elif method =='AUTO':\n",
    "                file.write(f\"- & \")\n",
    "            else:\n",
    "\n",
    "\n",
    "                if  str(round(row_std,1)) == '0.0':\n",
    "                    file.write(f\"{row:.1f}{flag} & \")\n",
    "                else:\n",
    "                    file.write(f\"{row:.1f}$\\\\pm${row_std:.1f}{flag} & \")\n",
    "\n",
    "\n",
    "\n",
    "        file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
