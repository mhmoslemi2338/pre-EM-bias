{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation of RR, PC, PQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize the overall correlation matrix\n",
    "correlation_matrix_all = np.zeros((3, 3))\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'\\\\stdBlock',\n",
    "    'QGramsBlocking':'\\\\qgram',\n",
    "    'ExtendedQGramsBlocking':'\\\\exQgram',\n",
    "    'SuffixArraysBlocking':'\\\\suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'\\\\exSuffix',\n",
    "    'AUTO':'\\\\AutoBlock',\n",
    "    'CTT':'\\\\CTT'}\n",
    "\n",
    "\n",
    "\n",
    "TASKS = ['Amazon-Google', 'Walmart-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM', 'Beer', 'Fodors-Zagat', 'iTunes-Amazon']\n",
    "file_path = 'Block_stat_final.txt'\n",
    "\n",
    "\n",
    "# Read the file and process the data\n",
    "data = []\n",
    "res = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into parts based on spaces\n",
    "        parts = line.split()\n",
    "        if parts == []: continue\n",
    "        if len(parts) == 2:\n",
    "            if parts[0] not in res.keys():\n",
    "                res[parts[0]] = {}\n",
    "            res[parts[0]][parts[1]] = {}\n",
    "            method = parts[1]\n",
    "            dataset = parts[0]\n",
    "            cnt = 0\n",
    "        elif parts[0] != 'bias':\n",
    "            RR = float(parts[0])\n",
    "            PC = float(parts[1])\n",
    "            PQ = float(parts[2])\n",
    "            time_ = float(parts[4])\n",
    "            Fb = 2*PC *RR / (PC + RR)\n",
    "            res[dataset][method] = {'RR':round(RR,5), 'PC':round(PC,5), 'PQ':round(PQ,5), 'Fb':round(Fb,5), 'time':round(time_,5)}\n",
    "        else:\n",
    "            if cnt ==0:\n",
    "                RR_minor = float(parts[1])\n",
    "                PC_minor = float(parts[2])\n",
    "                PQ_minor = float(parts[3])\n",
    "                Fb_minor = float(parts[4])\n",
    "                res[dataset][method]['RR_minor'] = round(RR_minor,5)\n",
    "                res[dataset][method]['PC_minor'] = round(PC_minor,5)\n",
    "                res[dataset][method]['PQ_minor'] = round(PQ_minor,5)\n",
    "                res[dataset][method]['Fb_minor'] = round(Fb_minor,5)\n",
    "                cnt+=1\n",
    "            elif cnt ==1:\n",
    "                RR_major = float(parts[1])\n",
    "                Pc_major = float(parts[2])\n",
    "                PQ_major = float(parts[3])\n",
    "                Fb_major = float(parts[4])\n",
    "                res[dataset][method]['RR_major'] = round(RR_major,5)\n",
    "                res[dataset][method]['Pc_major'] = round(Pc_major,5)\n",
    "                res[dataset][method]['PQ_major'] = round(PQ_major,5)\n",
    "                res[dataset][method]['Fb_major'] = round(Fb_major,5)\n",
    "                cnt+=1\n",
    "            elif cnt==2:\n",
    "\n",
    "                RR_diff = float(parts[1])\n",
    "                Pc_diff = float(parts[2])\n",
    "                PQ_diff = float(parts[3])\n",
    "                Fb_diff = float(parts[4])\n",
    "                res[dataset][method]['RR_diff'] = round(RR_diff,5)\n",
    "                res[dataset][method]['Pc_diff'] = round(Pc_diff,5)\n",
    "                res[dataset][method]['PQ_diff'] = round(PQ_diff,5)\n",
    "                res[dataset][method]['Fb_diff'] = round(Fb_diff,5)\n",
    "                cnt+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "# Iterate over tasks\n",
    "for i in range(7):\n",
    "    RR = []\n",
    "    PC = []\n",
    "    PQ = []\n",
    "    \n",
    "    # Calculate metrics for each method\n",
    "    for method in METHODS.keys():\n",
    "        task = TASKS[i]\n",
    "        row = res[task][method]\n",
    "        RR.append(row['RR'])\n",
    "        PC.append(row['PC'])\n",
    "        PQ.append(row['PQ'])\n",
    "\n",
    "    # Convert metrics to numpy arrays\n",
    "    rr = np.array(RR)\n",
    "    pc = np.array(PC)\n",
    "    pq = np.array(PQ)\n",
    "\n",
    "    # Create a DataFrame and compute the correlation matrix\n",
    "    data = pd.DataFrame({'RR': rr, 'PC': pc, 'PQ': pq})\n",
    "    correlation_matrix_all += np.abs(data.corr())\n",
    "\n",
    "# Plot the overall correlation heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "colorblind_palette = sns.color_palette(\"colorblind\", as_cmap=True)\n",
    "\n",
    "sns.heatmap(\n",
    "    (correlation_matrix_all / 7), \n",
    "    annot=True, \n",
    "    cmap=colorblind_palette, \n",
    "    center=0, \n",
    "    annot_kws={\"size\": 40, \"weight\": \"bold\"},\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "plt.xticks(fontsize=60)\n",
    "plt.yticks(fontsize=60)\n",
    "plt.tick_params(axis='both', which='both', length=10, width=3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FIGS/correlation_heatmap_all.pdf')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'stdBlck',\n",
    "    'QGramsBlocking':'QGram',\n",
    "    'ExtendedQGramsBlocking':'XQGram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'XSuffix',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TASKS = ['Amazon-Google', 'Walmart-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM', 'Beer', 'Fodors-Zagat', 'iTunes-Amazon']\n",
    "file_path = 'block_stat_time.txt'\n",
    "\n",
    "\n",
    "# Read the file and process the data\n",
    "data = []\n",
    "res = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into parts based on spaces\n",
    "        parts = line.split()\n",
    "        if parts == []: continue\n",
    "        try: \n",
    "            float(parts[0])\n",
    "            time_avg = float(parts[0])\n",
    "            time_std = float(parts[1])\n",
    "            res[dataset][method] = {'time_avg':round(time_avg,5), 'time_std':round(time_std,5)}\n",
    "        except:\n",
    "            if parts[0] not in res.keys():\n",
    "                res[parts[0]] = {}\n",
    "            res[parts[0]][parts[1]] = {}\n",
    "            method = parts[1]\n",
    "            dataset = parts[0]\n",
    "     \n",
    "\n",
    "\n",
    "res['Beer']['AUTO']  = {'time_avg': 9.16185941696167, 'time_std': 0.4758632559586421}\n",
    "res['iTunes-Amazon']['AUTO']= {'time_avg': 112.45368194580078, 'time_std': 3.491730883903146}\n",
    "res['Fodors-Zagat']['AUTO']= {'time_avg': 0.7223541736602783, 'time_std': 0.04316247998284229}\n",
    "res['Walmart-Amazon']['AUTO']= {'time_avg': 18.85678825378418, 'time_std': 0.5236079390049121}\n",
    "res['Amazon-Google']['AUTO']= {'time_avg': 5.152085638046264, 'time_std': 0.16152604483293306}\n",
    "res['DBLP-ACM']['AUTO']= {'time_avg': 7.0379444599151615, 'time_std': 0.2323224380155196}\n",
    "res['DBLP-GoogleScholar']['AUTO']= {'time_avg': 58.06285433769226, 'time_std': 2.8567257992252384}\n",
    "\n",
    "res['Beer']['CTT']  = {'time_avg': 10.189891958236695, 'time_std': 0.4049498209339713}\n",
    "res['iTunes-Amazon']['CTT']= {'time_avg': 156.71345224380494, 'time_std': 5.504195632915928}\n",
    "res['Fodors-Zagat']['CTT']= {'time_avg': 0.642644739151001, 'time_std': 0.015861690254546323}\n",
    "res['Walmart-Amazon']['CTT']= {'time_avg': 27.573931312561037, 'time_std': 5.267834604690219}\n",
    "res['Amazon-Google']['CTT']= {'time_avg': 5.319742012023926, 'time_std': 0.3558836507519921}\n",
    "res['DBLP-ACM']['CTT']= {'time_avg': 7.460848760604859, 'time_std': 0.18120981692447158}\n",
    "res['DBLP-GoogleScholar']['CTT']= {'time_avg': 89.94730200767518, 'time_std': 9.554257975921635}\n",
    "\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'stdBlck',\n",
    "    'QGramsBlocking':'QGram',\n",
    "    'ExtendedQGramsBlocking':'XQGram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'XSuffix',\n",
    "    'AUTO':'AUTO',\n",
    "    'CTT':'CTT'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colors = [\"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "colors = [\"#E69F00\", \"#33BFA1\", \"#007D59\", \"#56B4E9\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "\n",
    "markers = ['o', 's', 'D', '^', 'v', 'p', '*']\n",
    "\n",
    "\n",
    "colors = [\"#E69F00\", \"#33BFA1\", \"#007D59\", \"#56B4E9\",\"#0072B2\", \"#E15759\", \"#8B2B2E\"]#\n",
    "markers = ['o', 's', 'D', '^', 'v', '>', '<']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "\n",
    "for idx, M in enumerate(METHODS.keys()):\n",
    "    res_plot = []\n",
    "    for task in TASKS:\n",
    "        left_df = pd.read_csv(f\"data/{task}/tableA.csv\")\n",
    "        right_df = pd.read_csv(f\"data/{task}/tableB.csv\")\n",
    "\n",
    "        size_ = left_df.shape[0] * right_df.shape[0]\n",
    "        time_ = res[task][M]['time_avg']\n",
    "        time_std = res[task][M]['time_std']\n",
    "\n",
    "        # res_plot.append([np.log(size_), np.log(time_)])\n",
    "        res_plot.append([size_, \n",
    "                         time_, time_std])\n",
    "\n",
    "    res_plot.sort(key=lambda x: x[0])\n",
    "\n",
    "    plt.loglog(\n",
    "        [x[0] for x in res_plot],\n",
    "        [x[1] for x in res_plot],\n",
    "        marker=markers[idx % len(markers)],\n",
    "        color=colors[idx % len(colors)],\n",
    "        label=METHODS[M].replace('\\\\',''),\n",
    "        linestyle='-',  # Solid line\n",
    "        linewidth=4,\n",
    "        markersize=23\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"$|P_{init}|$: Initial pair pool size ($\\\\times 10^6$)\", fontsize=50)\n",
    "\n",
    "plt.ylabel(\"Time (sec)\",fontsize=50)\n",
    "current_ticks = plt.xticks()[0]\n",
    "new_ticks = current_ticks[1:-2:]\n",
    "plt.xticks(new_ticks,fontsize=48)\n",
    "plt.tick_params(axis='both', which='both', length=12, width=1.5)\n",
    "plt.yticks(fontsize=48)\n",
    "plt.legend(fontsize=48, loc='upper left', bbox_to_anchor=(0.005, 0.995), borderaxespad=0, handletextpad=0.2, borderpad=0.2, labelspacing=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FIGS/time_log.pdf')\n",
    "# plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for idx, M in enumerate(METHODS.keys()):\n",
    "    res_plot = []\n",
    "    for task in TASKS:\n",
    "        left_df = pd.read_csv(f\"data/{task}/tableA.csv\")\n",
    "        right_df = pd.read_csv(f\"data/{task}/tableB.csv\")\n",
    "\n",
    "        size_ = left_df.shape[0] * right_df.shape[0]\n",
    "        time_ = res[task][M]['time_avg']\n",
    "        time_std= res[task][M]['time_std']\n",
    "\n",
    "        # res_plot.append([np.log(size_), np.log(time_)])\n",
    "        res_plot.append([size_/1000000, \n",
    "                         time_/60, time_std/60])\n",
    "\n",
    "    res_plot.sort(key=lambda x: x[0])\n",
    "\n",
    "    plt.plot(\n",
    "        [x[0] for x in res_plot],\n",
    "        [x[1] for x in res_plot],\n",
    "        marker=markers[idx % len(markers)],\n",
    "        color=colors[idx % len(colors)],\n",
    "        label=METHODS[M].replace('\\\\',''),\n",
    "        linestyle='-',  # Solid line\n",
    "        linewidth=3.8,\n",
    "        markersize=16\n",
    "    )\n",
    "\n",
    "    # sizes = [x[0] for x in res_plot]\n",
    "    # times = [x[1] for x in res_plot]\n",
    "    # time_stds = [x[2] for x in res_plot]\n",
    "\n",
    "    # # plt.errorbar(\n",
    "    # #     sizes,\n",
    "    # #     times,\n",
    "    # #     yerr=time_stds,\n",
    "    # #     marker=markers[idx % len(markers)],\n",
    "    # #     color=colors[idx % len(colors)],\n",
    "    # #     label=METHODS[M].replace('\\\\', ''),\n",
    "    # #     linestyle='-',  # Solid line\n",
    "    # #     linewidth=3.8,\n",
    "    # #     markersize=16,\n",
    "    # #     capsize=5  # Controls the cap size of the error bars\n",
    "    # # )\n",
    "\n",
    "\n",
    "plt.xlabel(\"Initial pair pool size $|P_{init}|$ ($\\\\times 10^6$)\", fontsize=42)\n",
    "plt.ylabel(\"Time (min)\",fontsize=42)\n",
    "current_ticks = plt.xticks()[0]\n",
    "new_ticks = current_ticks[1::2]\n",
    "plt.xticks(new_ticks,fontsize=45)\n",
    "plt.tick_params(axis='both', which='both', length=12, width=1.5)\n",
    "plt.yticks(fontsize=45)\n",
    "plt.legend(fontsize=40, loc='upper left', bbox_to_anchor=(0.005, 0.995), borderaxespad=0, handletextpad=0.2, borderpad=0.2, labelspacing=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('FIGS/time.pdf')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time from same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_Walmart-Amazon.pdf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'stdBlck',\n",
    "    'ExtendedQGramsBlocking':'XQGram',\n",
    "    'ExtendedSuffixArraysBlocking':'XSuffix',\n",
    "    'QGramsBlocking':'QGram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "}\n",
    "\n",
    "TASKS = ['Amazon-Google', 'Walmart-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM', 'Beer', 'Fodors-Zagat', 'iTunes-Amazon']\n",
    "\n",
    "\n",
    "# for i in [2,3,4,5]:\n",
    "for i in [5]:\n",
    "\n",
    "        file_path = f'block_stat_time_same{i}.txt'\n",
    "\n",
    "\n",
    "        # Read the file and process the data\n",
    "        data = []\n",
    "        res = {}\n",
    "        time_ =[]\n",
    "\n",
    "        frac = []\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Split the line into parts based on spaces\n",
    "                parts = line.split()\n",
    "                if parts == []: \n",
    "                        res[dataset][method] = {'frac':frac, 'time':time_}\n",
    "                        continue\n",
    "                if parts[0] in TASKS:\n",
    "                    if parts[0] not in res.keys():\n",
    "                        res[parts[0]] = {}\n",
    "                        res[parts[0]][parts[1]] = {}\n",
    "                    frac = []\n",
    "                    time_ = []\n",
    "                    method = parts[1]\n",
    "                    dataset = parts[0]\n",
    "\n",
    "                else:\n",
    "                    frac.append(float(parts[0]))\n",
    "                    time_.append(float(parts[2]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        METHODS = {\n",
    "            'StandardBlocking':'stdBlck',\n",
    "            'QGramsBlocking':'QGram',\n",
    "            'ExtendedQGramsBlocking':'XQGram',\n",
    "            'SuffixArraysBlocking':'Suffix',\n",
    "            'ExtendedSuffixArraysBlocking':'XSuffix',\n",
    "            'AUTO':'AUTO',\n",
    "            'CTT':'CTT'\n",
    "        }\n",
    "\n",
    "\n",
    "        colors = [\"#E69F00\", \"#33BFA1\", \"#007D59\", \"#56B4E9\",\"#0072B2\", \"#D55E00\", \"#CC79A7\"]\n",
    "        markers = ['o', 's', 'D', '^', 'v', 'p', '*']\n",
    "\n",
    "\n",
    "\n",
    "        colors = [\"#E69F00\", \"#33BFA1\", \"#007D59\", \"#56B4E9\",\"#0072B2\", \"#E15759\", \"#8B2B2E\"]#\n",
    "        markers = ['o', 's', 'D', '^', 'v', '>', '<']\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(14, 12))\n",
    "\n",
    "\n",
    "        TT = list(res.keys())[0]\n",
    "        for idx, M in enumerate(METHODS.keys()):\n",
    "            res_plot = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if M == 'AUTO':\n",
    "                time_ = [\n",
    "                2.361281,\n",
    "                8.007564,\n",
    "                10.565273,\n",
    "                13.298214,\n",
    "                15.794987,\n",
    "                19.11888,\n",
    "            ]\n",
    "\n",
    "                frac = [0.01,0.2,0.4,0.6,0.8,1]\n",
    "            \n",
    "            elif M == 'CTT':\n",
    "                 \n",
    "                time_ = [2.569706153869629,\n",
    "                        10.010574245452881,\n",
    "                        14.817002058029175,\n",
    "                        20.32390217781067,\n",
    "                        21.906998586654662,\n",
    "                        25.958156061172485]\n",
    "                frac = [0.01,0.2,0.4,0.6,0.8,1]\n",
    "                \n",
    "\n",
    "            else:\n",
    "                 \n",
    "\n",
    "                time_ = res[TT][M]['time']\n",
    "                frac = res[TT][M]['frac']\n",
    "\n",
    "            # res_plot.append([frac, \n",
    "                                # time_])\n",
    "\n",
    "            # res_plot.sort(key=lambda x: x[0])\n",
    "\n",
    "            plt.plot(\n",
    "                100*np.array(frac),\n",
    "                time_,\n",
    "                marker=markers[idx % len(markers)],\n",
    "                color=colors[idx % len(colors)],\n",
    "                label=METHODS[M].replace('\\\\',''),\n",
    "                linestyle='-',  # Solid line\n",
    "                linewidth=4,\n",
    "                markersize=23\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        plt.xlabel(\"$\\\\frac{|P_{new}|}{|P_{init}|}$ (%)\",fontsize=50)\n",
    "        plt.ylabel(\"Time (sec)\",fontsize=50)\n",
    "        # current_ticks = plt.xticks()[0]\n",
    "        # new_ticks = current_ticks[1:-2:]\n",
    "        plt.xticks(fontsize=48)\n",
    "        plt.tick_params(axis='both', which='both', length=12, width=1.5)\n",
    "        plt.yticks(fontsize=48)\n",
    "        plt.legend(fontsize=48, loc='upper left', bbox_to_anchor=(0.005, 0.995), borderaxespad=0, handletextpad=0.2, borderpad=0.2, labelspacing=0.2)\n",
    "        # plt.close()\n",
    "        # plt.xlim([0-0.01,1+0.04])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig('FIGS/time_'+TT+'.pdf')\n",
    "        print('time_'+TT+'.pdf')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Define the path to your text file\n",
    "file_path = 'Block_stat_final.txt'\n",
    "\n",
    "\n",
    "# Read the file and process the data\n",
    "data = []\n",
    "res = {}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into parts based on spaces\n",
    "        parts = line.split()\n",
    "        if parts == []: continue\n",
    "        if len(parts) == 2:\n",
    "            if parts[0] not in res.keys():\n",
    "                res[parts[0]] = {}\n",
    "            res[parts[0]][parts[1]] = {}\n",
    "            method = parts[1]\n",
    "            dataset = parts[0]\n",
    "            cnt = 0\n",
    "        elif parts[0] != 'bias':\n",
    "            RR = float(parts[0])\n",
    "            PC = float(parts[1])\n",
    "            PQ = float(parts[2])\n",
    "            time_ = float(parts[4])\n",
    "            Fb = 2*PC *RR / (PC + RR)\n",
    "            res[dataset][method] = {'RR':round(RR,5), 'PC':round(PC,5), 'PQ':round(PQ,5), 'Fb':round(Fb,5), 'time':round(time_,5)}\n",
    "        else:\n",
    "            if cnt ==0:\n",
    "                RR_minor = float(parts[1])\n",
    "                PC_minor = float(parts[2])\n",
    "                PQ_minor = float(parts[3])\n",
    "                Fb_minor = float(parts[4])\n",
    "                res[dataset][method]['RR_minor'] = round(RR_minor,5)\n",
    "                res[dataset][method]['PC_minor'] = round(PC_minor,5)\n",
    "                res[dataset][method]['PQ_minor'] = round(PQ_minor,5)\n",
    "                res[dataset][method]['Fb_minor'] = round(Fb_minor,5)\n",
    "                cnt+=1\n",
    "            elif cnt ==1:\n",
    "                RR_major = float(parts[1])\n",
    "                Pc_major = float(parts[2])\n",
    "                PQ_major = float(parts[3])\n",
    "                Fb_major = float(parts[4])\n",
    "                res[dataset][method]['RR_major'] = round(RR_major,5)\n",
    "                res[dataset][method]['Pc_major'] = round(Pc_major,5)\n",
    "                res[dataset][method]['PQ_major'] = round(PQ_major,5)\n",
    "                res[dataset][method]['Fb_major'] = round(Fb_major,5)\n",
    "                cnt+=1\n",
    "            elif cnt==2:\n",
    "\n",
    "                RR_diff = float(parts[1])\n",
    "                Pc_diff = float(parts[2])\n",
    "                PQ_diff = float(parts[3])\n",
    "                Fb_diff = float(parts[4])\n",
    "                res[dataset][method]['RR_diff'] = round(RR_diff,5)\n",
    "                res[dataset][method]['Pc_diff'] = round(Pc_diff,5)\n",
    "                res[dataset][method]['PQ_diff'] = round(PQ_diff,5)\n",
    "                res[dataset][method]['Fb_diff'] = round(Fb_diff,5)\n",
    "                cnt+=1\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "M_all = list(res['Beer'].keys())\n",
    "\n",
    "scatter_pnt = {}\n",
    "for M in M_all:\n",
    "    scatter_pnt[M] = []\n",
    "\n",
    "\n",
    "for k in list(res.keys()):\n",
    "    for M in M_all:\n",
    "        # if M in ['CTT','AUTO'] and k == 'Fodors-Zagat': continue\n",
    "        scatter_pnt[M].append([res[k][M]['PC'],res[k][M]['PQ']])\n",
    "\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'stdBlck',\n",
    "    'QGramsBlocking':'QGram',\n",
    "    'ExtendedQGramsBlocking':'XQGram',\n",
    "    'SuffixArraysBlocking':'Suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'XSuffix',\n",
    "    'AUTO':'AUTO',\n",
    "    'CTT':'CTT'\n",
    "}\n",
    "\n",
    "\n",
    "colors = [\"#E69F00\", \"#33BFA1\", \"#007D59\", \"#56B4E9\",\"#0072B2\", \"#E15759\", \"#F28E2B\"]#8B2B2E\n",
    "markers = ['o', 's', 'D', '^', 'v', '>', '<']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for idx, M in enumerate(METHODS):\n",
    "    # if M in ['AUTO']: continue\n",
    "\n",
    "    row = np.array(scatter_pnt[M])\n",
    "    RR = (row[:,0])\n",
    "    PQ = (row[:,1])\n",
    "\n",
    "    plt.scatter(\n",
    "        PQ,\n",
    "        RR,\n",
    "        marker=markers[idx],\n",
    "        color=colors[idx],\n",
    "        label=METHODS[M].replace('\\\\',''),\n",
    "        # linestyle='-',  # Solid line\n",
    "        edgecolors='none',\n",
    "        linewidth=0,\n",
    "        s= 1000\n",
    "        # markersize=16\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"PC (%)\",fontsize=50)\n",
    "plt.ylabel(\"PQ (%)\",fontsize=50)\n",
    "# current_ticks = plt.xticks()[0]\n",
    "# new_ticks = current_ticks[1:-2:]\n",
    "plt.xticks(fontsize=45)\n",
    "plt.tick_params(axis='both', which='both', length=12, width=1.5)\n",
    "plt.yticks(fontsize=45)\n",
    "plt.legend(fontsize=40, borderaxespad=0, handletextpad=0.2, borderpad=0.2, labelspacing=0.2)\n",
    "# plt.close()\n",
    "# plt.xlim([0-0.01,1+0.04])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig('PQ-PC.pdf')\n",
    "# print('time_'+TT+'.pdf')\n",
    "# plt.xlim([-1,20])\n",
    "# plt.ylim([97.5,101])\n",
    "# plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = {}\n",
    "\n",
    "res['Beer']  ={'AUTO':[], 'CTT':[]}\n",
    "res['iTunes-Amazon']={'AUTO':[], 'CTT':[]}\n",
    "res['Fodors-Zagat']={'AUTO':[], 'CTT':[]}\n",
    "res['Walmart-Amazon']={'AUTO':[], 'CTT':[]}\n",
    "res['Amazon-Google']= {'AUTO':[], 'CTT':[]}\n",
    "res['DBLP-ACM']={'AUTO':[], 'CTT':[]}\n",
    "res['DBLP-GoogleScholar']= {'AUTO':[], 'CTT':[]}\n",
    "\n",
    "\n",
    "\n",
    "res['Beer']['AUTO']  = {'time_avg': 9.16185941696167, 'time_std': 0.4758632559586421}\n",
    "res['iTunes-Amazon']['AUTO']= {'time_avg': 112.45368194580078, 'time_std': 3.491730883903146}\n",
    "res['Fodors-Zagat']['AUTO']= {'time_avg': 0.7223541736602783, 'time_std': 0.04316247998284229}\n",
    "res['Walmart-Amazon']['AUTO']= {'time_avg': 18.85678825378418, 'time_std': 0.5236079390049121}\n",
    "res['Amazon-Google']['AUTO']= {'time_avg': 5.152085638046264, 'time_std': 0.16152604483293306}\n",
    "res['DBLP-ACM']['AUTO']= {'time_avg': 7.0379444599151615, 'time_std': 0.2323224380155196}\n",
    "res['DBLP-GoogleScholar']['AUTO']= {'time_avg': 58.06285433769226, 'time_std': 2.8567257992252384}\n",
    "\n",
    "res['Beer']['CTT']  = {'time_avg': 10.189891958236695, 'time_std': 0.4049498209339713}\n",
    "res['iTunes-Amazon']['CTT']= {'time_avg': 156.71345224380494, 'time_std': 5.504195632915928}\n",
    "res['Fodors-Zagat']['CTT']= {'time_avg': 0.642644739151001, 'time_std': 0.015861690254546323}\n",
    "res['Walmart-Amazon']['CTT']= {'time_avg': 27.573931312561037, 'time_std': 5.267834604690219}\n",
    "res['Amazon-Google']['CTT']= {'time_avg': 5.319742012023926, 'time_std': 0.3558836507519921}\n",
    "res['DBLP-ACM']['CTT']= {'time_avg': 7.460848760604859, 'time_std': 0.18120981692447158}\n",
    "res['DBLP-GoogleScholar']['CTT']= {'time_avg': 89.94730200767518, 'time_std': 9.554257975921635}\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    'StandardBlocking':'\\\\stdBlock',\n",
    "    'QGramsBlocking':'\\\\qgram',\n",
    "    'ExtendedQGramsBlocking':'\\\\exQgram',\n",
    "    'SuffixArraysBlocking':'\\\\suffix',\n",
    "    'ExtendedSuffixArraysBlocking':'\\\\exSuffix',\n",
    "    'AUTO':'\\\\AutoBlock',\n",
    "    'CTT':'\\\\CTT'}\n",
    "\n",
    "\n",
    "\n",
    "TASKS = ['Amazon-Google', 'Walmart-Amazon', 'DBLP-GoogleScholar', 'DBLP-ACM', 'Beer', 'Fodors-Zagat', 'iTunes-Amazon']\n",
    "\n",
    "\n",
    "for task in TASKS:\n",
    "    row = res[task]['AUTO']\n",
    "    time_ = row['time_avg']\n",
    "    std_ = row['time_std']\n",
    "\n",
    "    if time_ > 60:\n",
    "        time_ = time_ / 60\n",
    "        std_ = std_ / 60\n",
    "        print(task, round(time_,1), round(std_,1),'m')\n",
    "    else:\n",
    "        print(task, round(time_,1), round(std_,2),'s')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
